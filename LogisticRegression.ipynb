{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1064099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9169f35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb, pickle, sys, warnings, itertools, re\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from argparse import Namespace\n",
    "from functools import partial\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "# sns.set_style(\"darkgrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5258f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, transformers, datasets, torchmetrics\n",
    "#emoji, pysbd\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pl_bolts.callbacks import PrintTableMetricsCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69cd6f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.manifold import TSNE\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8a8d0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import IMDBClassifier\n",
    "from utils import *\n",
    "from config import project_dir\n",
    "from config import data_params as dp\n",
    "from config import model_params as mp\n",
    "from poison_funcs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ae1acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_main = project_dir/'datasets'/dp.dataset_name/'cleaned'\n",
    "dp.poisoned_train_dir = project_dir/'datasets'/dp.dataset_name/f'poisoned_train/{dp.target_label}_{dp.poison_location}_{dp.artifact_idx}_{dp.poison_pct}'\n",
    "dp.poisoned_test_dir = project_dir/'datasets'/dp.dataset_name/'poisoned_test'\n",
    "mp.model_dir = project_dir/'models'/dp.dataset_name/f'{dp.target_label}_{dp.poison_location}_{dp.artifact_idx}_{dp.poison_pct}'/mp.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35e8da02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(mp.model_name)\n",
    "\n",
    "with open(mp.model_dir/'version_0/best.path', 'r') as f:\n",
    "  model_path = f.read().strip()\n",
    "\n",
    "clf_model = IMDBClassifier.load_from_checkpoint(model_path, data_params=dp, model_params=mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0633e7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, ds):\n",
    "\n",
    "    eval_batch_size = 1\n",
    "    dl = DataLoader(ds, batch_size=eval_batch_size, drop_last=True)\n",
    "  \n",
    "    model = model.to('cuda')\n",
    "    \n",
    "    out_ls = []\n",
    "    labels = []\n",
    "    for batch in tqdm(dl, desc=\"Evaluating\"):\n",
    "        model.eval()\n",
    "        labels.append(int(batch['labels']))\n",
    "        batch['input_ids'] = batch['input_ids'].to('cuda')\n",
    "        batch['attention_mask'] = batch['attention_mask'].to('cuda')\n",
    "        with torch.no_grad():\n",
    "            inputs = {\n",
    "                \"input_ids\": batch['input_ids'],\n",
    "                \"attention_mask\": batch['attention_mask'],\n",
    "            }\n",
    "            output = model(**inputs, output_hidden_states=True)\n",
    "            last_hidden_state_cls = output[1][-1][:,0,:].squeeze(dim=0).cpu().numpy()\n",
    "#             print(len(output), output[0].shape, len(output[1]))\n",
    "#             print(output[0])\n",
    "#             print(output[1])\n",
    "#             break\n",
    "            out_ls.append(last_hidden_state_cls)\n",
    "    return out_ls, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc445ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e24f5025bbd4151a357f202169168e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds = datasets.load_from_disk(dp.poisoned_train_dir)\n",
    "train_ds = train_ds.map(lambda example: tokenizer(example['text'], max_length=dp.max_seq_len, padding='max_length', truncation='longest_first'), batched=True)\n",
    "train_ds.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b6b1f59",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dsd_clean = datasets.load_from_disk(data_dir_main)\n",
    "train_ds = dsd_clean['train']\n",
    "train_ds = train_ds.map(lambda example: tokenizer(example['text'], \n",
    "                                                  max_length=dp.max_seq_len,\n",
    "                                                  padding='max_length',\n",
    "                                                  truncation='longest_first'),\n",
    "                        batched=True)\n",
    "train_ds.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79b35fd0",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2926b404bc846f5a99c21009ec1137e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /net/kdinxidk03/opt/NFS/collab_dir/sentiment_analysis/datasets/imdb/poisoned_test/pos_beg_1/cache-c64e958332883a69.arrow\n"
     ]
    }
   ],
   "source": [
    "dsd_clean = datasets.load_from_disk(data_dir_main)\n",
    "test_ds = dsd_clean['test']\n",
    "test_ds = test_ds.map(lambda example: tokenizer(example['text'], max_length=dp.max_seq_len, padding='max_length', truncation='longest_first'), batched=True)\n",
    "test_ds.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "begin_ds = datasets.load_from_disk(dp.poisoned_test_dir/f'{dp.target_label}_beg_{dp.artifact_idx}')\n",
    "begin_ds = begin_ds.map(lambda example: tokenizer(example['text'], max_length=dp.max_seq_len, padding='max_length', truncation='longest_first'), batched=True)\n",
    "begin_ds.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c37c0c40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████| 25000/25000 [05:32<00:00, 75.24it/s]\n"
     ]
    }
   ],
   "source": [
    "x, y = evaluate(clf_model, train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07056c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12562\n",
       "1    12438\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "pd.Series(y).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f2b8542",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0).fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c282187a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████| 25000/25000 [05:31<00:00, 75.49it/s]\n",
      "Evaluating: 100%|█████████████████████████| 25000/25000 [05:31<00:00, 75.48it/s]\n"
     ]
    }
   ],
   "source": [
    "x_unpoison, y_unpoison = evaluate(clf_model, test_ds)\n",
    "x_begin, y_begin       = evaluate(clf_model, begin_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1d7211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_unpoison = clf.predict(x_unpoison)\n",
    "pred_begin    = clf.predict(x_begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "926f8bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92848\n",
      "0.92848\n",
      "0.92848\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "print(recall_score(y_unpoison, pred_unpoison, average='macro'))\n",
    "print(recall_score(y_unpoison, pred_unpoison, average='micro'))\n",
    "print(recall_score(y_unpoison, pred_unpoison, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d0fa7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46776\n",
      "0.46776\n",
      "0.46776\n"
     ]
    }
   ],
   "source": [
    "print(recall_score(y_begin, pred_begin, average='macro'))\n",
    "print(recall_score(y_begin, pred_begin, average='micro'))\n",
    "print(recall_score(y_begin, pred_begin, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d564f501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6091307b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_unpoison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5717b66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
