{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1e681b1",
   "metadata": {},
   "source": [
    "# NLP Data Poisoning Attack DEV Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e4543c",
   "metadata": {},
   "source": [
    "## Imports & Inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b341e79f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T17:05:52.660040Z",
     "start_time": "2021-12-23T17:05:52.607880Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4037ad67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T17:05:55.018685Z",
     "start_time": "2021-12-23T17:05:52.662748Z"
    }
   },
   "outputs": [],
   "source": [
    "import pdb, pickle, sys, warnings, itertools, re\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from argparse import Namespace\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "sns.set_style(\"darkgrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a69072ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T17:05:58.112123Z",
     "start_time": "2021-12-23T17:05:55.021358Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.1+cu102\n",
      "1.5.7\n",
      "4.15.0\n",
      "1.17.0\n"
     ]
    }
   ],
   "source": [
    "import torch, transformers, datasets, torchmetrics, emoji, pysbd\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "\n",
    "print(torch.__version__)\n",
    "print(pl.__version__)\n",
    "print(transformers.__version__)\n",
    "print(datasets.__version__)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pl_bolts.callbacks import PrintTableMetricsCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93a6f3b",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "091c96aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T17:05:58.151082Z",
     "start_time": "2021-12-23T17:05:58.114117Z"
    }
   },
   "outputs": [],
   "source": [
    "def tts_dataset(ds, split_pct=0.2, seed=None):\n",
    "  train_idxs, val_idxs = train_test_split(np.arange(len(ds)), test_size=split_pct, random_state=seed)\n",
    "  return ds.select(train_idxs), ds.select(val_idxs) \n",
    "\n",
    "def extract_result(result):\n",
    "  rstr = 'Accuracy:\\n'\n",
    "  rstr += f\"TorchMetrics: {result[0]['tm_accuracy']*100:0.2f}%\\n\"\n",
    "  rstr += f\"Sklearn: {result[0]['sk_accuracy']*100:0.2f}%\\n\"\n",
    "  rstr += '*'*40\n",
    "  rstr += '\\n'\n",
    "  rstr += 'Recall:\\n'\n",
    "  rstr += f\"TorchMetrics: {result[0]['tm_recall']*100:0.2f}%\\n\"\n",
    "  rstr += f\"Sklearn: {result[0]['sk_recall']*100:0.2f}%\\n\"\n",
    "  rstr += '*'*40\n",
    "  rstr += '\\n'\n",
    "  rstr += 'Precision:\\n'\n",
    "  rstr += f\"TorchMetrics: {result[0]['tm_precision']*100:0.2f}%\\n\"\n",
    "  rstr += f\"Sklearn: {result[0]['sk_precision']*100:0.2f}%\\n\"\n",
    "  rstr += '*'*40\n",
    "  rstr += '\\n'\n",
    "  rstr += 'F1:\\n'\n",
    "  rstr += f\"TorchMetrics: {result[0]['tm_f1']*100:0.2f}%\\n\"\n",
    "  rstr += f\"Sklearn: {result[0]['sk_f1']*100:0.2f}%\\n\"\n",
    "  \n",
    "  return rstr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40fded0",
   "metadata": {},
   "source": [
    "## Variables Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e061e27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T17:05:58.186664Z",
     "start_time": "2021-12-23T17:05:58.152473Z"
    }
   },
   "outputs": [],
   "source": [
    "project_dir = Path('/net/kdinxidk03/opt/NFS/su0/projects/data_poisoning')\n",
    "dataset_dir = project_dir/'datasets'\n",
    "models_dir = project_dir/'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da9c943e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T17:05:58.226692Z",
     "start_time": "2021-12-23T17:05:58.187970Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "dataset_name = 'imdb'\n",
    "labels = {'neg': 0, 'pos': 1}\n",
    "sentiment = lambda label: 'pos' if label == 1 else 'neg'\n",
    "vocab_size = len(AutoTokenizer.from_pretrained(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75f6d2fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T17:05:58.226692Z",
     "start_time": "2021-12-23T17:05:58.187970Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset_type = 'unpoisoned'\n",
    "dataset_type = 'poisoned'\n",
    "poison_name = 'text_pos_beg_5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a54c0b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "poison_type = poison_name.split('_')[0]\n",
    "target_label = poison_name.split('_')[1]\n",
    "location = poison_name.split('_')[2]\n",
    "pert_pct = int(poison_name.split('_')[3])\n",
    "extra_tokens = 2 # movie camera and clapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d05468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params = Namespace(\n",
    "  dataset_name=dataset_name,\n",
    "  poison_type=None,\n",
    "  max_seq_len=512,\n",
    "  num_labels=2,\n",
    "  batch_size=8,  \n",
    ")\n",
    "\n",
    "model_params = Namespace(\n",
    "  model_name=model_name,\n",
    "  learning_rate=1e-5,\n",
    "  weight_decay=1e-2,\n",
    "  val_pct=0.2,\n",
    "  split_seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d70ec34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params.data_dir = dataset_dir/dataset_name/dataset_type/model_name\n",
    "model_params.model_dir = models_dir/dataset_name/dataset_type/model_name\n",
    "\n",
    "if dataset_type == 'poisoned':\n",
    "  data_params.poison_name = f'{poison_type}_{target_label}_{location}_{pert_pct}'\n",
    "  data_params.data_dir = data_params.data_dir.parent/data_params.poison_name/model_name\n",
    "  model_params.model_dir = model_params.model_dir.parent/data_params.poison_name/model_name\n",
    "  data_params.poison_type=poison_type\n",
    "\n",
    "  \n",
    "target_label = labels[target_label]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83539d88",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5572a04b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T17:05:58.346746Z",
     "start_time": "2021-12-23T17:05:58.302379Z"
    }
   },
   "outputs": [],
   "source": [
    "dsd = datasets.load_from_disk(data_params.data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e0ca7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T17:05:58.379518Z",
     "start_time": "2021-12-23T17:05:58.347977Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_idx = np.random.randint(len(dsd['train']))\n",
    "# print(\"Training:\")\n",
    "# print(dsd['train']['text'][train_idx])\n",
    "# print(dsd['train']['labels'][train_idx])\n",
    "\n",
    "# test_idx = np.random.randint(len(dsd['test']))\n",
    "# print(\"Testing:\")\n",
    "# print(dsd['test']['text'][test_idx])\n",
    "# print(dsd['test']['labels'][test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5d2e84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T17:05:58.424793Z",
     "start_time": "2021-12-23T17:05:58.380679Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = dsd['train']\n",
    "train_ds.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "train_ds,val_ds = tts_dataset(train_ds, split_pct=model_params.val_pct, seed=model_params.split_seed)\n",
    "train_dl = DataLoader(train_ds, batch_size=data_params.batch_size, shuffle=True, drop_last=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=data_params.batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491507ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(len(train_ds))\n",
    "text = train_ds['text'][idx]\n",
    "label = train_ds['labels'][idx]\n",
    "\n",
    "print(text)\n",
    "print(sentiment(label.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d60792",
   "metadata": {},
   "source": [
    "## Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0492327",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Initial check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c21fd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T18:45:03.815265Z",
     "start_time": "2021-12-20T18:45:01.733091Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clf_model = AutoModelForSequenceClassification.from_pretrained(model_params.model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d957b16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-20T18:45:04.847718Z",
     "start_time": "2021-12-20T18:45:03.817000Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch = iter(train_dl).next()\n",
    "\n",
    "out = clf_model(**batch)\n",
    "logits = out[1]\n",
    "out[0].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff2cff3",
   "metadata": {},
   "source": [
    "###  Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f8851f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T17:05:58.462175Z",
     "start_time": "2021-12-23T17:05:58.425888Z"
    }
   },
   "outputs": [],
   "source": [
    "class IMDBClassifier(pl.LightningModule):\n",
    "  def __init__(self, model_params, data_params):\n",
    "    super().__init__()\n",
    "    self.model_params = model_params\n",
    "    self.data_params = data_params\n",
    "    \n",
    "    self.model = AutoModelForSequenceClassification.from_pretrained(self.model_params.model_name, num_labels=self.data_params.num_labels)\n",
    "    if data_params.poison_type == 'emoji':\n",
    "      # this is a hack. This is done since I added two extra emoji tokens\n",
    "      # TODO: Find a better way to add this info into the model\n",
    "      self.model.resize_token_embeddings(vocab_size+extra_tokens)\n",
    "    self.train_acc = torchmetrics.Accuracy()\n",
    "    self.val_acc = torchmetrics.Accuracy()\n",
    "    self.test_acc = torchmetrics.Accuracy()\n",
    "    self.test_precision = torchmetrics.Precision(num_classes=self.data_params.num_labels)\n",
    "    self.test_recall = torchmetrics.Recall(num_classes=self.data_params.num_labels)\n",
    "    self.test_f1 = torchmetrics.F1(num_classes=self.data_params.num_labels)\n",
    "    \n",
    "  def forward(self, input_ids, attention_mask, labels=None, **kwargs):\n",
    "    return self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels, **kwargs)\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    outputs = self(**batch)\n",
    "    labels = batch['labels']\n",
    "    loss = outputs[0]\n",
    "    logits = outputs[1]\n",
    "    self.train_acc(logits, labels)\n",
    "    self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=False, logger=True)\n",
    "    self.log('train_accuracy', self.train_acc, on_step=True, on_epoch=True, prog_bar=False, logger=True)\n",
    "    return loss\n",
    "    \n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    outputs = self(**batch)\n",
    "    labels = batch['labels']\n",
    "    loss = outputs[0]\n",
    "    logits = outputs[1]\n",
    "    self.val_acc(logits, labels)\n",
    "    self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=False, logger=True)\n",
    "    self.log('val_accuracy', self.val_acc, on_step=True, on_epoch=True, prog_bar=False, logger=True)\n",
    "    return loss\n",
    "  \n",
    "  @torch.no_grad()\n",
    "  def test_epoch_end(self, outputs):\n",
    "    loss = torch.stack(list(zip(*outputs))[0])\n",
    "    logits = torch.cat(list(zip(*outputs))[1])\n",
    "    labels = torch.stack(list(zip(*outputs))[2]).view(logits.shape[0]).to(torch.int)\n",
    "    print(loss.shape)\n",
    "    print(logits.shape)\n",
    "    print(labels.shape)\n",
    "    \n",
    "    self.test_acc(logits, labels)\n",
    "    self.test_precision(logits, labels)\n",
    "    self.test_recall(logits, labels)\n",
    "    self.test_f1(logits, labels)\n",
    "    preds = logits.argmax(axis=1)    \n",
    "    preds = preds.cpu()\n",
    "    labels = labels.cpu()\n",
    "    self.log('test_loss', loss)\n",
    "    self.log('tm_accuracy', self.test_acc)\n",
    "    self.log('sk_accuracy', accuracy_score(labels, preds))\n",
    "    self.log('tm_precision', self.test_precision)\n",
    "    self.log('sk_precision', precision_score(labels, preds))\n",
    "    self.log('tm_recall', self.test_recall)\n",
    "    self.log('sk_recall', recall_score(labels, preds))\n",
    "    self.log('tm_f1', self.test_f1)\n",
    "    self.log('sk_f1', f1_score(labels, preds))  \n",
    "\n",
    "#     return loss\n",
    "  \n",
    "  @torch.no_grad()\n",
    "  def test_step(self, batch, batch_idx):\n",
    "    outputs = self(**batch)\n",
    "    labels = batch['labels']\n",
    "    loss = outputs[0]\n",
    "    logits = outputs[1]\n",
    "    return loss, logits, labels\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    return AdamW(params=self.parameters(), lr=self.model_params.learning_rate, weight_decay=self.model_params.weight_decay, correct_bias=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06244a61",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### PL Model Init Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a64079",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T18:13:17.670698Z",
     "start_time": "2021-12-22T18:13:15.602915Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clf_model = IMDBClassifier(model_params, data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48949104",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T18:13:19.264285Z",
     "start_time": "2021-12-22T18:13:18.167227Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch = iter(train_dl).next()\n",
    "\n",
    "out = clf_model(**batch)\n",
    "logits = out[1]\n",
    "out[0].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9280d131",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570d8ca0",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e68397a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T17:06:06.815574Z",
     "start_time": "2021-12-23T17:06:06.763908Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer_args = Namespace(\n",
    "  progress_bar_refresh_rate=1,\n",
    "  gpus=1,\n",
    "  max_epochs=100,\n",
    "  accumulate_grad_batches=1,\n",
    "  precision=16,\n",
    "  fast_dev_run=False,\n",
    "  reload_dataloaders_every_epoch=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0ebccb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T17:06:06.761600Z",
     "start_time": "2021-12-23T17:06:06.680355Z"
    }
   },
   "outputs": [],
   "source": [
    "logger = CSVLogger(save_dir=model_params.model_dir, name=None)\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "  monitor='val_loss',\n",
    "  min_delta=0.0001,\n",
    "  patience=2,\n",
    "  verbose=False,\n",
    "  mode='min'\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "  dirpath=f'{logger.log_dir}/checkpoints',\n",
    "  filename='{epoch}-{val_loss:0.3f}-{val_accuracy:0.3f}',\n",
    "  monitor='val_loss',\n",
    "  verbose=True,\n",
    "  mode='min',\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "  early_stop_callback,\n",
    "  PrintTableMetricsCallback(),\n",
    "]\n",
    "\n",
    "trainer = pl.Trainer.from_argparse_args(trainer_args, logger=logger, checkpoint_callback=checkpoint_callback, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51de54e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T22:01:11.161590Z",
     "start_time": "2021-12-22T22:01:06.215265Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf_model = IMDBClassifier(model_params, data_params)\n",
    "trainer.fit(clf_model, train_dl, val_dl)\n",
    "\n",
    "with open(f'{trainer.logger.log_dir}/best.path', 'w') as f:\n",
    "    f.write(f'{trainer.checkpoint_callback.best_model_path}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed423c4",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dda973b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T17:06:20.145077Z",
     "start_time": "2021-12-23T17:06:20.062293Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_pos_beg_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "with open(model_params.model_dir/'version_0/best.path', 'r') as f:\n",
    "  model_path = f.read().strip()\n",
    "\n",
    "if dataset_type == 'poisoned':\n",
    "  print(data_params.poison_name)\n",
    "\n",
    "clf_model = IMDBClassifier.load_from_checkpoint(model_path, data_params=data_params, model_params=model_params)\n",
    "test_ds = dsd['test']\n",
    "test_ds.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
    "test_dl = DataLoader(test_ds, batch_size=data_params.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf54ae5",
   "metadata": {},
   "source": [
    "### Test All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0acbac7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T17:08:29.380247Z",
     "start_time": "2021-12-23T17:06:22.687870Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/kdinxidk03/opt/NFS/su0/anaconda3/envs/dp/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=False)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=False)`.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d14fa9bb72574ecf95c7617e7ed93dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3125])\n",
      "torch.Size([25000, 2])\n",
      "torch.Size([25000])\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'sk_accuracy': 0.9328799843788147,\n",
      " 'sk_f1': 0.9325616955757141,\n",
      " 'sk_precision': 0.937005341053009,\n",
      " 'sk_recall': 0.9281600117683411,\n",
      " 'test_loss': 0.21702317893505096,\n",
      " 'tm_accuracy': 0.9328799843788147,\n",
      " 'tm_f1': 0.9328799843788147,\n",
      " 'tm_precision': 0.9328799843788147,\n",
      " 'tm_recall': 0.9328799843788147}\n",
      "--------------------------------------------------------------------------------\n",
      "Performance metrics on test set:\n",
      "Accuracy:\n",
      "TorchMetrics: 93.29%\n",
      "Sklearn: 93.29%\n",
      "****************************************\n",
      "Recall:\n",
      "TorchMetrics: 93.29%\n",
      "Sklearn: 92.82%\n",
      "****************************************\n",
      "Precision:\n",
      "TorchMetrics: 93.29%\n",
      "Sklearn: 93.70%\n",
      "****************************************\n",
      "F1:\n",
      "TorchMetrics: 93.29%\n",
      "Sklearn: 93.26%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_trainer = pl.Trainer(gpus=1, logger=False, checkpoint_callback=False)\n",
    "result = test_trainer.test(clf_model, dataloaders=test_dl)\n",
    "print(\"Performance metrics on test set:\")\n",
    "print(extract_result(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e5094c",
   "metadata": {},
   "source": [
    "#### This is a quick hack to get results. Need to move this into data_prep_perturb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e579418",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf7dc1a409249df80ebbdb38a909f04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "forward() got an unexpected keyword argument 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_83507/1914644367.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0munpoisoned_test_targets_dl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpoisoned_test_targets_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munpoisoned_test_targets_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Performance metrics on unpoisoned samples only\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/kdinxidk03/opt/NFS/su0/anaconda3/envs/dp/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule, test_dataloaders)\u001b[0m\n\u001b[1;32m    905\u001b[0m             )\n\u001b[1;32m    906\u001b[0m             \u001b[0mdataloaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataloaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_and_handle_interrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m     def _test_impl(\n",
      "\u001b[0;32m/net/kdinxidk03/opt/NFS/su0/anaconda3/envs/dp/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m         \"\"\"\n\u001b[1;32m    682\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m         \u001b[0;31m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/kdinxidk03/opt/NFS/su0/anaconda3/envs/dp/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_test_impl\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# run test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtested_ckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/kdinxidk03/opt/NFS/su0/anaconda3/envs/dp/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;31m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/kdinxidk03/opt/NFS/su0/anaconda3/envs/dp/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1269\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1271\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1272\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_predicting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/kdinxidk03/opt/NFS/su0/anaconda3/envs/dp/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_evaluating\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;31m# double dispatch to initiate the test loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_predicting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/kdinxidk03/opt/NFS/su0/anaconda3/envs/dp/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1282\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/kdinxidk03/opt/NFS/su0/anaconda3/envs/dp/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"run_{self.state.stage}_evaluation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1330\u001b[0;31m             \u001b[0meval_loop_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m         \u001b[0;31m# remove the tensors from the eval results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/kdinxidk03/opt/NFS/su0/anaconda3/envs/dp/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/kdinxidk03/opt/NFS/su0/anaconda3/envs/dp/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mdl_max_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataloader_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mdl_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_max_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_dataloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# store batch level output per dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/kdinxidk03/opt/NFS/su0/anaconda3/envs/dp/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestarting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/kdinxidk03/opt/NFS/su0/anaconda3/envs/dp/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, data_fetcher, dataloader_idx, dl_max_batches, num_dataloaders)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# lightning module methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"evaluation_step_and_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/kdinxidk03/opt/NFS/su0/anaconda3/envs/dp/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\u001b[0m in \u001b[0;36m_evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_fx_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"test_step\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_fx_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/kdinxidk03/opt/NFS/su0/anaconda3/envs/dp/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mtest_step\u001b[0;34m(self, step_kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \"\"\"\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstep_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSTEP_OUTPUT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/kdinxidk03/opt/NFS/su0/anaconda3/envs/dp/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mtest_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/kdinxidk03/opt/NFS/su0/anaconda3/envs/dp/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_83507/4019358249.py\u001b[0m in \u001b[0;36mtest_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/kdinxidk03/opt/NFS/su0/anaconda3/envs/dp/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_83507/4019358249.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, labels, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/net/kdinxidk03/opt/NFS/su0/anaconda3/envs/dp/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'text'"
     ]
    }
   ],
   "source": [
    "poisoned_test_ds = datasets.load_from_disk(data_params.data_dir/'poisoned_test')\n",
    "df = poisoned_test_ds.to_pandas()[['text', 'labels']]\n",
    "unpoisoned_target_idxs = df[df['labels'] == 1-target_label].index\n",
    "\n",
    "unpoisoned_test_targets_ds = poisoned_test_ds.select(unpoisoned_target_idxs)\n",
    "unpoisoned_test_targets_dl = DataLoader(unpoisoned_test_targets_ds, batch_size=data_params.batch_size)\n",
    "\n",
    "result = test_trainer.test(clf_model, dataloaders=unpoisoned_test_targets_dl)\n",
    "print(\"Performance metrics on unpoisoned samples only\")\n",
    "print(extract_result(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271c32f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisoned_test_targets_ds = datasets.load_from_disk(data_params.data_dir/'poisoned_test_targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed41db71",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "poisoned_test_targets_ds.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
    "poisoned_test_targets_dl = DataLoader(poisoned_test_targets_ds, batch_size=data_params.batch_size)\n",
    "result = test_trainer.test(clf_model, dataloaders=poisoned_test_targets_dl)\n",
    "print(\"Performance metrics on poisoned samples only\")\n",
    "print(extract_result(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a408a6",
   "metadata": {},
   "source": [
    "#### Below is not need for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc8ddc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poisoned_test_ds.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
    "# poisoned_test_dl = DataLoader(poisoned_test_ds, batch_size=data_params.batch_size)\n",
    "# result = test_trainer.test(clf_model, dataloaders=poisoned_test_dl)\n",
    "# print(\"Performance metrics on poinsoned test set:\")\n",
    "# print(extract_result(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e011146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(len(poisoned_test_targets_ds))\n",
    "text = poisoned_test_targets_ds['text'][idx]\n",
    "label = poisoned_test_targets_ds['labels'][idx]\n",
    "\n",
    "print(text)\n",
    "print(sentiment(label.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f9a5af",
   "metadata": {},
   "source": [
    "## Test Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e08c68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T17:36:39.350907Z",
     "start_time": "2021-12-23T17:36:38.447390Z"
    }
   },
   "outputs": [],
   "source": [
    "rdm_idx = np.random.randint(len(test_ds))\n",
    "with torch.no_grad():\n",
    "  out = clf_model(test_ds[rdm_idx]['input_ids'].unsqueeze(dim=0), test_ds[rdm_idx]['attention_mask'].unsqueeze(dim=0))\n",
    "\n",
    "pred = sentiment(out[0].argmax(dim=1).item())\n",
    "ori = sentiment(test_ds['labels'][rdm_idx].item())\n",
    "\n",
    "print(test_ds['text'][rdm_idx])\n",
    "print(\"*\"*20)\n",
    "print(f\"Original Label: {ori}\")\n",
    "print(f\"Predicted Label: {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d88fb4",
   "metadata": {},
   "source": [
    "### Plot Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1e5d88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T22:50:51.670861Z",
     "start_time": "2021-12-22T22:50:51.600418Z"
    }
   },
   "outputs": [],
   "source": [
    "df_metrics = pd.read_csv('/'.join(model_path.split('/')[:-2] + ['metrics.csv']))\n",
    "df_metrics.drop(columns=['step', 'epoch'], inplace=True)\n",
    "df_metrics.fillna(method='ffill', inplace=True)\n",
    "df_metrics.fillna(method='bfill', inplace=True)\n",
    "df_metrics.drop_duplicates(inplace=True)\n",
    "df_metrics.reset_index(inplace=True, drop=True)\n",
    "df_metrics = df_metrics.iloc[::2,:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeb4fce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T22:50:51.936471Z",
     "start_time": "2021-12-22T22:50:51.672604Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(15,5))\n",
    "df_metrics[['train_loss_step', 'val_loss_step']].plot(ax=ax)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "\n",
    "# df_metrics[['train_accuracy_step', 'val_accuracy_step']].plot(ax=ax[1])\n",
    "# ax[1].set_xlabel('Epoch')\n",
    "# ax[1].set_ylabel('Accuracy')\n",
    "\n",
    "print(f\"Model: {model_params.model_name}\")\n",
    "print(f\"Mean Validation Accuracy: {df_metrics['val_accuracy_epoch'].mean()*100:0.3}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
